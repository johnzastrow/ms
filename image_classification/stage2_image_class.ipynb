{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "mount_file_id": "1uKwm40yem75CcjJjiRwFI3r4DkWBl8tv",
   "authorship_tag": "ABX9TyPZMycfp7ZFwxY/2Fj0yDAI"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "d677be8e49f64f8aab5afb4ef69c7264": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9af660dd23434b63818eb7839d5247a7",
       "IPY_MODEL_eed6a22d78fd420581822853ca630448",
       "IPY_MODEL_2644bed47a9d46e5aa6ef43aef77aa82"
      ],
      "layout": "IPY_MODEL_3d0dece50251421c9d979788dc668ae3"
     }
    },
    "9af660dd23434b63818eb7839d5247a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_898ab3d94ce34843931ede7790a47073",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_b674fa014f8a4d65b850cf9c7a450b58",
      "value": "Publishing:\u2007100%"
     }
    },
    "eed6a22d78fd420581822853ca630448": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9622b78450c94d10b54eb027c61905e0",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f878832c75c84e94bc30eefde410f156",
      "value": 500
     }
    },
    "2644bed47a9d46e5aa6ef43aef77aa82": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4ff002789c8440a8459c96e2def137e",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_54a71488e1664c52b87657ceecdba9c6",
      "value": "\u2007500/500\u2007[00:21&lt;00:00,\u200733.62it/s]"
     }
    },
    "3d0dece50251421c9d979788dc668ae3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "898ab3d94ce34843931ede7790a47073": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b674fa014f8a4d65b850cf9c7a450b58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9622b78450c94d10b54eb027c61905e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f878832c75c84e94bc30eefde410f156": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4ff002789c8440a8459c96e2def137e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54a71488e1664c52b87657ceecdba9c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9cd2f78a0e84243972a55b5d3ce1246": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_249c0dd3cb4a4135a261adbf60a112e5",
       "IPY_MODEL_eefeb9d6152e461383459a7be48b652e",
       "IPY_MODEL_8e6d543880b24c72b7dd55edf86708b6"
      ],
      "layout": "IPY_MODEL_9e8c45754d3b4a669f17499553645872"
     }
    },
    "249c0dd3cb4a4135a261adbf60a112e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1102da428764c6b9c3cac0ae6c1bfd2",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_26899b40c00d49e0b4539f2331f81fe8",
      "value": "CNN\u2007Processing:\u2007100%"
     }
    },
    "eefeb9d6152e461383459a7be48b652e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2aa6dccac6c44b42a68c4e29048ab2a0",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d05afd7e72554780b931c43ed25e2cba",
      "value": 500
     }
    },
    "8e6d543880b24c72b7dd55edf86708b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4676d10a60a47058e7f7b38c61d8f02",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_3f139f5528c24c5592ce7cdc914e96ce",
      "value": "\u2007499/500\u2007[01:27&lt;00:00,\u200712.86it/s]"
     }
    },
    "9e8c45754d3b4a669f17499553645872": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a1102da428764c6b9c3cac0ae6c1bfd2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26899b40c00d49e0b4539f2331f81fe8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2aa6dccac6c44b42a68c4e29048ab2a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d05afd7e72554780b931c43ed25e2cba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4676d10a60a47058e7f7b38c61d8f02": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f139f5528c24c5592ce7cdc914e96ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9ad8f327916468ab58463dca1527164": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_507f2554c0f447b1a7cfeb78f81c459f",
       "IPY_MODEL_f08949b74204451d818566d7f2f0a29a",
       "IPY_MODEL_46010ad417da4d40b3571c272615759a"
      ],
      "layout": "IPY_MODEL_4de8b246265a46e5b2a829dd49d9d574"
     }
    },
    "507f2554c0f447b1a7cfeb78f81c459f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75c67aed4a024188aa7f962fcbec4a42",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_052b579a7f6e47c7accc40bfd9f23a31",
      "value": "ResNet\u2007Processing:\u2007\u2007\u20070%"
     }
    },
    "f08949b74204451d818566d7f2f0a29a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8f492eb1cc749508d826d1012760814",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d27ee41a78504b399720e7b18588bb47",
      "value": 500
     }
    },
    "46010ad417da4d40b3571c272615759a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fde2b1484ba044518e67145af756b9a9",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_359361e4fa2149f89166bf23d20dc024",
      "value": "\u20071/500\u2007[00:00&lt;02:12,\u2007\u20073.78it/s]"
     }
    },
    "4de8b246265a46e5b2a829dd49d9d574": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "75c67aed4a024188aa7f962fcbec4a42": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "052b579a7f6e47c7accc40bfd9f23a31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8f492eb1cc749508d826d1012760814": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d27ee41a78504b399720e7b18588bb47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fde2b1484ba044518e67145af756b9a9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "359361e4fa2149f89166bf23d20dc024": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# **Agentic AI for Image Classification (Stage 2: Expanded)**\n\nThis builds on Stage 1 improvements and adds new capabilities:\n\n**Stage 1 improvements (carried forward):**\n- Fixed ResNet augmentation bug, enhanced data augmentation, full test set evaluation\n- Per-class metrics, confusion matrices, training history plots\n- Improved Judge strategy, reproducibility seeds, model save/load\n- Kafka decoupled, error handling in agents\n\n**Stage 2 new capabilities:**\n- **2.1** Third model agent (MobileNetV2 with transfer learning)\n- **2.2** Soft voting ensemble across all three agents\n- **2.10** CSV export of results and McNemar's statistical test\n\nSee [NEXT_STEPS.md](NEXT_STEPS.md) for full rationale behind each enhancement.",
   "metadata": {
    "id": "snE03lqIlFsS"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Step 1: Setup Required Packages & Verify Kafka\nKafka and Zookeeper must be running as external services before starting this notebook.\nSee [RUN_ON_VPS.md](RUN_ON_VPS.md) for setup instructions.",
   "metadata": {
    "id": "HCDFMH3clB9S"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcKzhMvTkorP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770820123494,
     "user_tz": 300,
     "elapsed": 126450,
     "user": {
      "displayName": "Michael Hynes",
      "userId": "11107330966821812196"
     }
    },
    "outputId": "ad467bbf-dfee-456b-c6fc-e3cfead8ea20"
   },
   "outputs": [],
   "source": "# Stage 2: Additional packages for statistical analysis\n# Install Python packages (Kafka must already be running as a system service)\n\n!pip install tensorflow keras numpy matplotlib kafka-python pillow tqdm scikit-learn seaborn scipy pandas\n\n# Verify Kafka is reachable\nimport time\nfrom kafka import KafkaProducer\n\ntry:\n    p = KafkaProducer(bootstrap_servers=['localhost:9092'])\n    p.close()\n    print(\"Kafka is reachable\")\nexcept Exception as e:\n    raise RuntimeError(\n        \"Kafka is not running. Start Kafka and Zookeeper before running this notebook.\\n\"\n        \"See RUN_ON_VPS.md for setup instructions.\"\n    ) from e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Load CIFAR-10 Data and setup functions"
   ],
   "metadata": {
    "id": "8urwOlHjlujp"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Stage 2: Added MobileNet topic and model path\n# Step 2: Load CIFAR-10 and create helper functions\n\nimport os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.datasets import cifar10\nfrom PIL import Image\nimport csv\nimport pandas as pd\n\n# Set seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# CIFAR-10 class names\nCIFAR10_CLASSES = [\n    'airplane', 'automobile', 'bird', 'cat', 'deer',\n    'dog', 'frog', 'horse', 'ship', 'truck'\n]\n\n# Topics for message broker (Stage 2: added MobileNet topic)\nREQUEST_TOPIC = 'cifar_classification_requests'\nCNN_RESPONSE_TOPIC = 'cnn_classifications'\nRESNET_RESPONSE_TOPIC = 'resnet_classifications'\nMOBILENET_RESPONSE_TOPIC = 'mobilenet_classifications'\n\n# Model paths for save/load\nMODEL_DIR = 'saved_models'\nos.makedirs(MODEL_DIR, exist_ok=True)\nCNN_PATH = os.path.join(MODEL_DIR, 'cnn_cifar_model.keras')\nRESNET_PATH = os.path.join(MODEL_DIR, 'resnet_cifar_model.keras')\nMOBILENET_PATH = os.path.join(MODEL_DIR, 'mobilenet_cifar_model.keras')\n\n# Load CIFAR-10 dataset\nprint(\"Loading CIFAR-10 dataset...\")\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n# Normalize pixel values (0-255 -> 0-1)\nx_train = x_train.astype('float32') / 255.0\nx_test = x_test.astype('float32') / 255.0\n\n# Flatten labels\ny_train = y_train.flatten()\ny_test = y_test.flatten()\n\nprint(f\"Training images: {x_train.shape}\")\nprint(f\"Test images: {x_test.shape}\")\n\n\ndef get_random_test_image():\n    \"\"\"Get a random test image with its metadata\"\"\"\n    idx = np.random.randint(0, len(x_test))\n    return {\n        'image_id': idx,\n        'image_data': x_test[idx].tolist(),\n        'true_label': int(y_test[idx]),\n        'true_class': CIFAR10_CLASSES[y_test[idx]]\n    }\n\n\ndef decode_prediction(predictions):\n    \"\"\"Convert model output to class name and confidence\"\"\"\n    predicted_class = np.argmax(predictions)\n    confidence = float(predictions[predicted_class])\n    return {\n        'predicted_class': int(predicted_class),\n        'predicted_name': CIFAR10_CLASSES[predicted_class],\n        'confidence': confidence\n    }\n\ndef numpy_to_json(arr):\n    \"\"\"Convert numpy array to JSON-serializable format\"\"\"\n    return json.dumps(arr.tolist())\n\ndef json_to_numpy(json_str):\n    \"\"\"Convert JSON string back to numpy array\"\"\"\n    return np.array(json.loads(json_str))\n\n# Display a sample image\nimport matplotlib.pyplot as plt\n\nsample = get_random_test_image()\nplt.figure(figsize=(6, 6))\nplt.imshow(np.array(sample['image_data']))\nplt.title(f\"Sample Image: {sample['true_class']} (Label: {sample['true_label']})\\nImage ID: {sample['image_id']}\")\nplt.axis('off')\nplt.show()\nprint(f\"CIFAR-10 classes: {CIFAR10_CLASSES}\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "e9CAkqrXl9G9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770820147149,
     "user_tz": 300,
     "elapsed": 23652,
     "user": {
      "displayName": "Michael Hynes",
      "userId": "11107330966821812196"
     }
    },
    "outputId": "a3fb0c0f-9919-4a67-d74e-fcd105a563fa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Build & train the CNN Model"
   ],
   "metadata": {
    "id": "6wEVH2x_mEEt"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Stage 1 improvements: 1.2 (augmentation), 1.3 (full test set), 1.8 (save/load)\n# Step 3: Build and train the CNN model\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping\n\ndef build_cnn_model():\n    model = models.Sequential([\n      # BLOCK 1: DATA AUGMENTATION (Stage 1 improvement 1.2)\n      layers.RandomFlip(\"horizontal\", input_shape=(32, 32, 3)),\n      layers.RandomRotation(0.05),\n      layers.RandomZoom(0.1),\n      layers.RandomTranslation(0.1, 0.1),\n\n      # BLOCK 2: INITIAL FEATURE EXTRACTION\n      layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n      layers.BatchNormalization(),\n      layers.Conv2D(32, (3, 3), activation='relu'),\n      layers.BatchNormalization(),\n      layers.MaxPooling2D(pool_size=(2, 2)),\n      layers.Dropout(0.2),\n\n      # BLOCK 3: SECONDARY FEATURE MAPPING\n      layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n      layers.BatchNormalization(),\n      layers.MaxPooling2D(pool_size=(2, 2)),\n      layers.Dropout(0.3),\n\n      # BLOCK 4: CLASSIFIER HEAD\n      layers.Flatten(),\n      layers.Dense(128, activation='relu'),\n      layers.BatchNormalization(),\n      layers.Dropout(0.5),\n      layers.Dense(10, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer='adam',\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n\n# Stage 1 improvement 1.8: Load saved model if available, otherwise train\nif os.path.exists(CNN_PATH):\n    print(f\"Loading pre-trained CNN model from {CNN_PATH}...\")\n    cnn_model = keras.models.load_model(CNN_PATH)\n    history_cnn = None\n    test_loss, test_acc = cnn_model.evaluate(x_test, y_test, verbose=0)\n    print(f\"CNN Test Accuracy: {test_acc*100:.2f}%\")\nelse:\n    print(\"Building and training CNN model...\")\n    cnn_model = build_cnn_model()\n    cnn_model.summary()\n\n    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n    history_cnn = cnn_model.fit(\n        x_train,\n        y_train,\n        epochs=50,\n        batch_size=64,\n        validation_split=0.2,\n        callbacks=[early_stop]\n    )\n\n    # Stage 1 improvement 1.3: Evaluate on FULL test set\n    test_loss, test_acc = cnn_model.evaluate(x_test, y_test, verbose=0)\n    print(f\"CNN Test Accuracy (full test set): {test_acc*100:.2f}%\")\n\n    # Save the trained model\n    cnn_model.save(CNN_PATH)\n    print(f\"CNN model saved to {CNN_PATH}\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Cmmc7FIfmER9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770820299827,
     "user_tz": 300,
     "elapsed": 152676,
     "user": {
      "displayName": "Michael Hynes",
      "userId": "11107330966821812196"
     }
    },
    "outputId": "4b158638-ce61-4cbe-8ade-75c1129105cf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Step 3b: CNN Evaluation - Confusion Matrix & Training History\nStage 1 improvements 1.4 (per-class metrics) and 1.5 (training history plots)",
   "metadata": {
    "id": "Lm2_HozqlvPs"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Stage 1 improvements 1.4 and 1.5: Confusion matrix and training curves for CNN\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\ny_pred_cnn = np.argmax(cnn_model.predict(x_test), axis=1)\ncm_cnn = confusion_matrix(y_test, y_pred_cnn)\n\nfig, axes = plt.subplots(1, 2, figsize=(18, 6))\n\n# Confusion matrix\nsns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues',\n            xticklabels=CIFAR10_CLASSES, yticklabels=CIFAR10_CLASSES, ax=axes[0])\naxes[0].set_title('CNN Confusion Matrix')\naxes[0].set_ylabel('True Label')\naxes[0].set_xlabel('Predicted Label')\naxes[0].tick_params(axis='x', rotation=45)\n\n# Training curves (only if we trained this session)\nif history_cnn is not None:\n    axes[1].plot(history_cnn.history['accuracy'], label='Train Accuracy')\n    axes[1].plot(history_cnn.history['val_accuracy'], label='Val Accuracy')\n    axes[1].plot(history_cnn.history['loss'], label='Train Loss', linestyle='--')\n    axes[1].plot(history_cnn.history['val_loss'], label='Val Loss', linestyle='--')\n    axes[1].set_title('CNN Training History')\n    axes[1].legend()\n    axes[1].set_xlabel('Epoch')\n    axes[1].set_ylabel('Value')\nelse:\n    axes[1].text(0.5, 0.5, 'Model loaded from disk\\n(no training history)',\n                 ha='center', va='center', fontsize=14)\n    axes[1].set_title('CNN Training History')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nCNN Classification Report:\")\nprint(classification_report(y_test, y_pred_cnn, target_names=CIFAR10_CLASSES))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Stage 1 improvements: 1.1 (bug fix), 1.2 (augmentation), 1.3 (full test set), 1.8 (save/load)\n# Step 4: Build and train the ResNet model\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\ndef build_resnet_model():\n    inputs = layers.Input(shape=(32, 32, 3))\n\n    # Stage 1 improvement 1.1: FIXED - augmentation output now feeds into Conv2D\n    # Stage 1 improvement 1.2: Added rotation, zoom, translation\n    x = layers.RandomFlip(\"horizontal\")(inputs)\n    x = layers.RandomRotation(0.05)(x)\n    x = layers.RandomZoom(0.1)(x)\n    x = layers.RandomTranslation(0.1, 0.1)(x)\n\n    # Initial Convolutional Layer -- uses x (not inputs)\n    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n\n    # REUSABLE RESIDUAL BLOCK FUNCTION\n    def residual_block(x, filters, downsample=False):\n        shortcut = x\n        stride = (2, 2) if downsample else (1, 1)\n\n        # SHORTCUT - Adjust shortcut if dimensions change\n        if downsample or x.shape[-1] != filters:\n            shortcut = layers.Conv2D(filters, (1, 1), strides=stride, padding='same')(shortcut)\n            shortcut = layers.BatchNormalization()(shortcut)\n\n        # BLOCK - First Conv\n        x = layers.Conv2D(filters, (3, 3), strides=stride, padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation('relu')(x)\n\n        # BLOCK - Second Conv\n        x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n        x = layers.BatchNormalization()(x)\n\n        # ADDITION AND THEN ACTIVATION\n        x = layers.Dropout(0.2)(x)\n        x = layers.add([x, shortcut])\n        x = layers.Activation('relu')(x)\n        return x\n\n    # Model Backbone\n    x = residual_block(x, 64)\n    x = residual_block(x, 128, downsample=True)  # Downsamples to 16x16\n    x = residual_block(x, 256, downsample=True)  # Downsamples to 8x8\n\n    # Modern Classifier Head\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(10, activation='softmax')(x)\n\n    model = models.Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n\n# Stage 1 improvement 1.8: Load saved model if available, otherwise train\nif os.path.exists(RESNET_PATH):\n    print(f\"Loading pre-trained ResNet model from {RESNET_PATH}...\")\n    resnet_model = keras.models.load_model(RESNET_PATH)\n    history_resnet = None\n    test_loss, test_acc = resnet_model.evaluate(x_test, y_test, verbose=0)\n    print(f\"ResNet Test Accuracy: {test_acc*100:.2f}%\")\nelse:\n    print(\"Building and training ResNet model...\")\n    resnet_model = build_resnet_model()\n    resnet_model.summary()\n\n    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n    lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n\n    history_resnet = resnet_model.fit(\n        x_train, y_train,\n        epochs=50,\n        batch_size=64,\n        validation_split=0.2,\n        callbacks=[early_stop, lr_callback]\n    )\n\n    # Stage 1 improvement 1.3: Evaluate on FULL test set\n    test_loss, test_acc = resnet_model.evaluate(x_test, y_test, verbose=0)\n    print(f\"ResNet Test Accuracy (full test set): {test_acc*100:.2f}%\")\n\n    # Save the trained model\n    resnet_model.save(RESNET_PATH)\n    print(f\"ResNet model saved to {RESNET_PATH}\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xgpBv-hKmQMB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770820567274,
     "user_tz": 300,
     "elapsed": 267440,
     "user": {
      "displayName": "Michael Hynes",
      "userId": "11107330966821812196"
     }
    },
    "outputId": "5826e97d-2152-4eb6-b7ca-0fd13662ef0d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Stage 1 improvements 1.4 and 1.5: Confusion matrix and training curves for ResNet\n\ny_pred_resnet = np.argmax(resnet_model.predict(x_test), axis=1)\ncm_resnet = confusion_matrix(y_test, y_pred_resnet)\n\nfig, axes = plt.subplots(1, 2, figsize=(18, 6))\n\n# Confusion matrix\nsns.heatmap(cm_resnet, annot=True, fmt='d', cmap='Reds',\n            xticklabels=CIFAR10_CLASSES, yticklabels=CIFAR10_CLASSES, ax=axes[0])\naxes[0].set_title('ResNet Confusion Matrix')\naxes[0].set_ylabel('True Label')\naxes[0].set_xlabel('Predicted Label')\naxes[0].tick_params(axis='x', rotation=45)\n\n# Training curves (only if we trained this session)\nif history_resnet is not None:\n    axes[1].plot(history_resnet.history['accuracy'], label='Train Accuracy')\n    axes[1].plot(history_resnet.history['val_accuracy'], label='Val Accuracy')\n    axes[1].plot(history_resnet.history['loss'], label='Train Loss', linestyle='--')\n    axes[1].plot(history_resnet.history['val_loss'], label='Val Loss', linestyle='--')\n    axes[1].set_title('ResNet Training History')\n    axes[1].legend()\n    axes[1].set_xlabel('Epoch')\n    axes[1].set_ylabel('Value')\nelse:\n    axes[1].text(0.5, 0.5, 'Model loaded from disk\\n(no training history)',\n                 ha='center', va='center', fontsize=14)\n    axes[1].set_title('ResNet Training History')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nResNet Classification Report:\")\nprint(classification_report(y_test, y_pred_resnet, target_names=CIFAR10_CLASSES))",
   "metadata": {
    "id": "dx6H2sek7p2w",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770820567285,
     "user_tz": 300,
     "elapsed": 6,
     "user": {
      "displayName": "Michael Hynes",
      "userId": "11107330966821812196"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Step 4b: Build & Train the MobileNetV2 Model (Stage 2 Enhancement 2.1)\nThis demonstrates transfer learning -- using a model architecture pre-trained on ImageNet and training it on CIFAR-10. MobileNetV2 is a lightweight architecture designed for mobile and edge devices.",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Stage 2 enhancement 2.1: MobileNetV2 transfer learning agent\n# Step 4b: Build and train the MobileNetV2 model\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\ndef build_mobilenet_model():\n    \"\"\"Build MobileNetV2 for CIFAR-10 (32x32 input, no pre-trained weights)\"\"\"\n    base_model = keras.applications.MobileNetV2(\n        input_shape=(32, 32, 3),\n        include_top=False,\n        weights=None  # ImageNet weights require >= 96x96 input\n    )\n\n    model = models.Sequential([\n        layers.RandomFlip(\"horizontal\", input_shape=(32, 32, 3)),\n        layers.RandomRotation(0.05),\n        layers.RandomZoom(0.1),\n        layers.RandomTranslation(0.1, 0.1),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(10, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer='adam',\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n\n# Load saved model if available, otherwise train\nif os.path.exists(MOBILENET_PATH):\n    print(f\"Loading pre-trained MobileNet model from {MOBILENET_PATH}...\")\n    mobilenet_model = keras.models.load_model(MOBILENET_PATH)\n    history_mobilenet = None\n    test_loss, test_acc = mobilenet_model.evaluate(x_test, y_test, verbose=0)\n    print(f\"MobileNet Test Accuracy: {test_acc*100:.2f}%\")\nelse:\n    print(\"Building and training MobileNetV2 model...\")\n    mobilenet_model = build_mobilenet_model()\n    mobilenet_model.summary()\n\n    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n    lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n\n    history_mobilenet = mobilenet_model.fit(\n        x_train, y_train,\n        epochs=50,\n        batch_size=64,\n        validation_split=0.2,\n        callbacks=[early_stop, lr_callback]\n    )\n\n    test_loss, test_acc = mobilenet_model.evaluate(x_test, y_test, verbose=0)\n    print(f\"MobileNet Test Accuracy (full test set): {test_acc*100:.2f}%\")\n\n    mobilenet_model.save(MOBILENET_PATH)\n    print(f\"MobileNet model saved to {MOBILENET_PATH}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# MobileNet confusion matrix and training curves\n\ny_pred_mobilenet = np.argmax(mobilenet_model.predict(x_test), axis=1)\ncm_mobilenet = confusion_matrix(y_test, y_pred_mobilenet)\n\nfig, axes = plt.subplots(1, 2, figsize=(18, 6))\n\n# Confusion matrix\nsns.heatmap(cm_mobilenet, annot=True, fmt='d', cmap='Greens',\n            xticklabels=CIFAR10_CLASSES, yticklabels=CIFAR10_CLASSES, ax=axes[0])\naxes[0].set_title('MobileNetV2 Confusion Matrix')\naxes[0].set_ylabel('True Label')\naxes[0].set_xlabel('Predicted Label')\naxes[0].tick_params(axis='x', rotation=45)\n\n# Training curves\nif history_mobilenet is not None:\n    axes[1].plot(history_mobilenet.history['accuracy'], label='Train Accuracy')\n    axes[1].plot(history_mobilenet.history['val_accuracy'], label='Val Accuracy')\n    axes[1].plot(history_mobilenet.history['loss'], label='Train Loss', linestyle='--')\n    axes[1].plot(history_mobilenet.history['val_loss'], label='Val Loss', linestyle='--')\n    axes[1].set_title('MobileNetV2 Training History')\n    axes[1].legend()\n    axes[1].set_xlabel('Epoch')\n    axes[1].set_ylabel('Value')\nelse:\n    axes[1].text(0.5, 0.5, 'Model loaded from disk\\n(no training history)',\n                 ha='center', va='center', fontsize=14)\n    axes[1].set_title('MobileNetV2 Training History')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nMobileNetV2 Classification Report:\")\nprint(classification_report(y_test, y_pred_mobilenet, target_names=CIFAR10_CLASSES))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5: Build the CNN Agent (Publisher/Subscriber)"
   ],
   "metadata": {
    "id": "Tm-6BojNmfJK"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Stage 1 improvement 1.10: Error handling added to agents\n# Step 5: CNN Agent - Listens for requests and classifies images\n\nimport json\nimport time\nfrom kafka import KafkaConsumer, KafkaProducer\nimport numpy as np\nimport logging\n\nlogging.getLogger('kafka').setLevel(logging.CRITICAL)\n\ndef run_cnn_agent(max_messages=100):\n    try:\n        consumer = KafkaConsumer(\n            REQUEST_TOPIC,\n            bootstrap_servers=['localhost:9092'],\n            group_id='cnn_classifier_group',\n            auto_offset_reset='latest',\n            value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n            consumer_timeout_ms=60000\n        )\n\n        producer = KafkaProducer(\n            bootstrap_servers=['localhost:9092'],\n            value_serializer=lambda v: json.dumps(v).encode('utf-8')\n        )\n    except Exception as e:\n        print(f\"CNN AGENT ERROR: Failed to connect to Kafka: {e}\")\n        return\n\n    print(\"CNN-CIFAR AGENT is ready and listening for requests\")\n\n    message_count = 0\n    for message in consumer:\n        try:\n            request = message.value\n            image_id = request['image_id']\n\n            image_data = np.array(request['image_data'])\n            image_batch = np.expand_dims(image_data, axis=0)\n\n            start_time = time.time()\n            predictions = cnn_model.predict(image_batch, verbose=0)[0]\n            inference_time = time.time() - start_time\n\n            result = decode_prediction(predictions)\n\n            response = {\n                'agent': 'CNN-CIFAR',\n                'image_id': image_id,\n                'true_label': request['true_label'],\n                'true_class': request['true_class'],\n                'predicted_class': result['predicted_class'],\n                'predicted_name': result['predicted_name'],\n                'confidence': result['confidence'],\n                'probabilities': predictions.tolist(),\n                'inference_time_ms': inference_time * 1000,\n                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n            }\n\n            producer.send(CNN_RESPONSE_TOPIC, value=response)\n\n        except Exception as e:\n            print(f\"CNN AGENT ERROR processing message: {e}\")\n            continue\n\n        message_count += 1\n        if message_count >= max_messages:\n            break\n\n    producer.flush()\n    consumer.close()\n\nprint(\"CNN Agent function created and ready!\")\n\nimport threading\nthreading.Thread(target=run_cnn_agent, daemon=True).start()\nprint(\"CNN Agent is now running in the background...\")\ntime.sleep(2)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjUwUjF-mgxr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770820569360,
     "user_tz": 300,
     "elapsed": 2073,
     "user": {
      "displayName": "Michael Hynes",
      "userId": "11107330966821812196"
     }
    },
    "outputId": "ca558b4c-b3a5-48f7-fabc-272123fb0d3f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 6: Build the ResNet Agent"
   ],
   "metadata": {
    "id": "iRJquCRlml4b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Stage 1 improvement 1.10: Error handling added to agents\n# Step 6: ResNet Agent - Listens for requests and classifies images\n\nlogging.getLogger('kafka').setLevel(logging.CRITICAL)\n\ndef run_resnet_agent(max_messages=100):\n    try:\n        consumer = KafkaConsumer(\n            REQUEST_TOPIC,\n            bootstrap_servers=['localhost:9092'],\n            group_id='resnet_classifier_group',\n            auto_offset_reset='latest',\n            value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n            consumer_timeout_ms=60000\n        )\n\n        producer = KafkaProducer(\n            bootstrap_servers=['localhost:9092'],\n            value_serializer=lambda v: json.dumps(v).encode('utf-8')\n        )\n    except Exception as e:\n        print(f\"RESNET AGENT ERROR: Failed to connect to Kafka: {e}\")\n        return\n\n    print(\"RESNET-CIFAR AGENT is ready and listening for requests...\")\n\n    message_count = 0\n    for message in consumer:\n        try:\n            request = message.value\n            image_id = request['image_id']\n\n            image_data = np.array(request['image_data'])\n            image_batch = np.expand_dims(image_data, axis=0)\n\n            start_time = time.time()\n            predictions = resnet_model.predict(image_batch, verbose=0)[0]\n            inference_time = time.time() - start_time\n\n            result = decode_prediction(predictions)\n\n            response = {\n                'agent': 'RESNET-CIFAR',\n                'image_id': image_id,\n                'true_label': request['true_label'],\n                'true_class': request['true_class'],\n                'predicted_class': result['predicted_class'],\n                'predicted_name': result['predicted_name'],\n                'confidence': result['confidence'],\n                'probabilities': predictions.tolist(),\n                'inference_time_ms': inference_time * 1000,\n                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n            }\n\n            producer.send(RESNET_RESPONSE_TOPIC, value=response)\n\n        except Exception as e:\n            print(f\"RESNET AGENT ERROR processing message: {e}\")\n            continue\n\n        message_count += 1\n        if message_count >= max_messages:\n            break\n\n    producer.flush()\n    consumer.close()\n\nprint(\"ResNet Agent function created and ready!\")\n\nimport threading\nthreading.Thread(target=run_resnet_agent, daemon=True).start()\nprint(\"ResNet Agent is now running in the background...\")\ntime.sleep(2)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XDmQ4fHmmNc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770820571364,
     "user_tz": 300,
     "elapsed": 2002,
     "user": {
      "displayName": "Michael Hynes",
      "userId": "11107330966821812196"
     }
    },
    "outputId": "eebd3886-d379-4881-ae70-e92fa712ba27"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Step 6b: Build the MobileNet Agent (Stage 2 Enhancement 2.1)",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Stage 2 enhancement 2.1: MobileNet Agent\n# Step 6b: MobileNet Agent - Listens for requests and classifies images\n\ndef run_mobilenet_agent(max_messages=100):\n    try:\n        consumer = KafkaConsumer(\n            REQUEST_TOPIC,\n            bootstrap_servers=['localhost:9092'],\n            group_id='mobilenet_classifier_group',\n            auto_offset_reset='latest',\n            value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n            consumer_timeout_ms=60000\n        )\n\n        producer = KafkaProducer(\n            bootstrap_servers=['localhost:9092'],\n            value_serializer=lambda v: json.dumps(v).encode('utf-8')\n        )\n    except Exception as e:\n        print(f\"MOBILENET AGENT ERROR: Failed to connect to Kafka: {e}\")\n        return\n\n    print(\"MOBILENET-CIFAR AGENT is ready and listening for requests...\")\n\n    message_count = 0\n    for message in consumer:\n        try:\n            request = message.value\n            image_id = request['image_id']\n\n            image_data = np.array(request['image_data'])\n            image_batch = np.expand_dims(image_data, axis=0)\n\n            start_time = time.time()\n            predictions = mobilenet_model.predict(image_batch, verbose=0)[0]\n            inference_time = time.time() - start_time\n\n            result = decode_prediction(predictions)\n\n            response = {\n                'agent': 'MOBILENET-CIFAR',\n                'image_id': image_id,\n                'true_label': request['true_label'],\n                'true_class': request['true_class'],\n                'predicted_class': result['predicted_class'],\n                'predicted_name': result['predicted_name'],\n                'confidence': result['confidence'],\n                'probabilities': predictions.tolist(),\n                'inference_time_ms': inference_time * 1000,\n                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n            }\n\n            producer.send(MOBILENET_RESPONSE_TOPIC, value=response)\n\n        except Exception as e:\n            print(f\"MOBILENET AGENT ERROR processing message: {e}\")\n            continue\n\n        message_count += 1\n        if message_count >= max_messages:\n            break\n\n    producer.flush()\n    consumer.close()\n\nprint(\"MobileNet Agent function created and ready!\")\n\nimport threading\nthreading.Thread(target=run_mobilenet_agent, daemon=True).start()\nprint(\"MobileNet Agent is now running in the background...\")\ntime.sleep(2)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 7: Build the Judge Agent"
   ],
   "metadata": {
    "id": "xvFKlrmBmuEQ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Stage 2 enhancement 2.2: Three-agent soft voting ensemble\n# Step 7: Judge Agent - Sends requests to all 3 agents, compares with soft voting\n\nimport json\nimport time\nfrom kafka import KafkaProducer, KafkaConsumer\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\n\ndef run_judge_agent(num_images=500):\n    try:\n        request_producer = KafkaProducer(\n            bootstrap_servers=['localhost:9092'],\n            value_serializer=lambda v: json.dumps(v).encode('utf-8')\n        )\n\n        cnn_consumer = KafkaConsumer(\n            CNN_RESPONSE_TOPIC,\n            bootstrap_servers=['localhost:9092'],\n            group_id=f'judge_cnn_{int(time.time())}',\n            auto_offset_reset='earliest',\n            value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n            consumer_timeout_ms=10000\n        )\n\n        resnet_consumer = KafkaConsumer(\n            RESNET_RESPONSE_TOPIC,\n            bootstrap_servers=['localhost:9092'],\n            group_id=f'judge_resnet_{int(time.time())}',\n            auto_offset_reset='earliest',\n            value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n            consumer_timeout_ms=10000\n        )\n\n        mobilenet_consumer = KafkaConsumer(\n            MOBILENET_RESPONSE_TOPIC,\n            bootstrap_servers=['localhost:9092'],\n            group_id=f'judge_mobilenet_{int(time.time())}',\n            auto_offset_reset='earliest',\n            value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n            consumer_timeout_ms=10000\n        )\n    except Exception as e:\n        print(f\"JUDGE AGENT ERROR: Failed to connect to Kafka: {e}\")\n        return None\n\n    print(f\"JUDGE AGENT: Submitting {num_images} images to Broker (3 agents)...\")\n\n    # Publish requests\n    for _ in tqdm(range(num_images), desc=\"Publishing\"):\n        image_request = get_random_test_image()\n        request_producer.send(REQUEST_TOPIC, value=image_request)\n        time.sleep(0.01)\n\n    request_producer.flush()\n\n    # Collect results from all 3 agents\n    cnn_results = []\n    with tqdm(total=num_images, desc=\"CNN Processing\", leave=False) as pbar:\n        for message in cnn_consumer:\n            cnn_results.append(message.value)\n            pbar.update(1)\n            if len(cnn_results) >= num_images: break\n\n    resnet_results = []\n    with tqdm(total=num_images, desc=\"ResNet Processing\", leave=False) as pbar:\n        for message in resnet_consumer:\n            resnet_results.append(message.value)\n            pbar.update(1)\n            if len(resnet_results) >= num_images: break\n\n    mobilenet_results = []\n    with tqdm(total=num_images, desc=\"MobileNet Processing\", leave=False) as pbar:\n        for message in mobilenet_consumer:\n            mobilenet_results.append(message.value)\n            pbar.update(1)\n            if len(mobilenet_results) >= num_images: break\n\n    # Cleanup\n    cnn_consumer.close()\n    resnet_consumer.close()\n    mobilenet_consumer.close()\n    request_producer.close()\n\n    # Build comparison map\n    comparison_map = defaultdict(dict)\n\n    for r in cnn_results:\n        comparison_map[r['image_id']]['cnn'] = r\n    for r in resnet_results:\n        comparison_map[r['image_id']]['resnet'] = r\n    for r in mobilenet_results:\n        comparison_map[r['image_id']]['mobilenet'] = r\n\n    # Track performance\n    cnn_total_correct = 0\n    resnet_total_correct = 0\n    mobilenet_total_correct = 0\n    ensemble_total_correct = 0\n    all_agree_count = 0\n    images_with_all_responses = 0\n\n    for img_id, results in comparison_map.items():\n        if 'cnn' in results and 'resnet' in results and 'mobilenet' in results:\n            images_with_all_responses += 1\n\n            cnn_res = results['cnn']\n            res_res = results['resnet']\n            mob_res = results['mobilenet']\n            true_label = cnn_res['true_label']\n\n            # Individual accuracy\n            if cnn_res['predicted_class'] == true_label:\n                cnn_total_correct += 1\n            if res_res['predicted_class'] == true_label:\n                resnet_total_correct += 1\n            if mob_res['predicted_class'] == true_label:\n                mobilenet_total_correct += 1\n\n            # Check agreement\n            preds = [cnn_res['predicted_class'], res_res['predicted_class'], mob_res['predicted_class']]\n            if len(set(preds)) == 1:\n                all_agree_count += 1\n\n            # Stage 2 enhancement 2.2: Soft voting ensemble\n            # Average probability vectors from all 3 agents\n            cnn_probs = np.array(cnn_res['probabilities'])\n            resnet_probs = np.array(res_res['probabilities'])\n            mobilenet_probs = np.array(mob_res['probabilities'])\n            ensemble_probs = (cnn_probs + resnet_probs + mobilenet_probs) / 3.0\n            ensemble_pred = int(np.argmax(ensemble_probs))\n\n            if ensemble_pred == true_label:\n                ensemble_total_correct += 1\n\n    return {\n        'total': images_with_all_responses,\n        'cnn_correct': cnn_total_correct,\n        'resnet_correct': resnet_total_correct,\n        'mobilenet_correct': mobilenet_total_correct,\n        'ensemble_correct': ensemble_total_correct,\n        'all_agree_count': all_agree_count,\n        'comparison_map': dict(comparison_map)\n    }\n\nprint(\"Judge Agent function ready (3-agent soft voting)\")\ntime.sleep(2)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_zCu7tK9muW6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770820573431,
     "user_tz": 300,
     "elapsed": 2063,
     "user": {
      "displayName": "Michael Hynes",
      "userId": "11107330966821812196"
     }
    },
    "outputId": "f7573f4e-f2bf-49e5-e3ca-508a7bf793f6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 8: Run All Agents with Threading"
   ],
   "metadata": {
    "id": "uvkHtpTUm50q"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Step 8: Orchestration (3 agents + Judge)\n\nimport threading\n\ndef run_complete_system(num_test_images=500):\n    final_output = []\n\n    def judge_wrapper():\n        res = run_judge_agent(num_images=num_test_images)\n        final_output.append(res)\n\n    cnn_thread = threading.Thread(\n        target=run_cnn_agent,\n        args=(num_test_images,),\n        daemon=True\n    )\n    resnet_thread = threading.Thread(\n        target=run_resnet_agent,\n        args=(num_test_images,),\n        daemon=True\n    )\n    mobilenet_thread = threading.Thread(\n        target=run_mobilenet_agent,\n        args=(num_test_images,),\n        daemon=True\n    )\n    judge_thread = threading.Thread(target=judge_wrapper)\n\n    # Start all agent threads\n    cnn_thread.start()\n    resnet_thread.start()\n    mobilenet_thread.start()\n    time.sleep(2)\n\n    # Start and wait for judge\n    judge_thread.start()\n    judge_thread.join()\n    time.sleep(2)\n\n    return final_output[0] if final_output else None\n\nprint(\"System orchestration function ready (3 agents)!\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XtHjHTEm5-Q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770820573441,
     "user_tz": 300,
     "elapsed": 6,
     "user": {
      "displayName": "Michael Hynes",
      "userId": "11107330966821812196"
     }
    },
    "outputId": "44b1686a-c6f1-42ce-c6af-ae900c996dd0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Stage 1 improvement 1.9: Kafka restart removed\nKafka is managed as an external system service. No restart cell needed.\nSee [RUN_ON_VPS.md](RUN_ON_VPS.md) for Kafka management instructions.",
   "metadata": {
    "id": "OLFIMm1rHPd3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 10: Execute the System & Visualize Performance"
   ],
   "metadata": {
    "id": "ocTEs7CgnDSO"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Step 10: Full Scale Test and Visualization (3 agents + ensemble)\n\nimport matplotlib.pyplot as plt\nimport logging\n\nlogging.getLogger('kafka').setLevel(logging.ERROR)\n\nif __name__ == \"__main__\":\n    TOTAL_IMAGES = 500\n    print(f\"Executing Broker Test: Processing {TOTAL_IMAGES} images across 3 agents...\")\n    stats = run_complete_system(num_test_images=TOTAL_IMAGES)\n\n    if stats:\n        actual_total = stats.get('total', TOTAL_IMAGES)\n        all_agree = stats.get('all_agree_count', 0)\n\n        labels = ['CNN', 'ResNet', 'MobileNet', 'Ensemble\\n(Soft Vote)']\n        counts = [\n            stats['cnn_correct'],\n            stats['resnet_correct'],\n            stats['mobilenet_correct'],\n            stats['ensemble_correct']\n        ]\n        accuracies = [(c / actual_total) * 100 for c in counts]\n\n        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n        # Accuracy bar chart\n        colors = ['#3498db', '#e74c3c', '#f39c12', '#2ecc71']\n        bars = axes[0].bar(labels, accuracies, color=colors, edgecolor='black', alpha=0.8)\n\n        for bar, count in zip(bars, counts):\n            height = bar.get_height()\n            axes[0].text(bar.get_x() + bar.get_width()/2., height + 1,\n                     f'{height:.1f}%\\n({count}/{actual_total})',\n                     ha='center', va='bottom', fontweight='bold')\n\n        axes[0].set_title(f'3-Agent Classification Performance (n={actual_total})',\n                          fontsize=14, fontweight='bold')\n        axes[0].set_ylabel('Accuracy %')\n        axes[0].set_ylim(0, 115)\n        axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n\n        # Agreement pie chart\n        disagree = actual_total - all_agree\n        axes[1].pie([all_agree, disagree],\n                    labels=[f'All 3 Agreed\\n({all_agree})', f'Disagreed\\n({disagree})'],\n                    colors=['#2ecc71', '#e67e22'], autopct='%1.1f%%',\n                    startangle=90, textprops={'fontweight': 'bold'})\n        axes[1].set_title(f'3-Agent Agreement Rate (n={actual_total})',\n                          fontsize=14, fontweight='bold')\n\n        plt.tight_layout()\n        plt.show()\n\n        print(f\"\\nSummary:\")\n        print(f\"  CNN Accuracy:      {accuracies[0]:.1f}% ({counts[0]}/{actual_total})\")\n        print(f\"  ResNet Accuracy:   {accuracies[1]:.1f}% ({counts[1]}/{actual_total})\")\n        print(f\"  MobileNet Accuracy:{accuracies[2]:.1f}% ({counts[2]}/{actual_total})\")\n        print(f\"  Ensemble Accuracy: {accuracies[3]:.1f}% ({counts[3]}/{actual_total})\")\n        print(f\"  All 3 Agreed:      {all_agree}/{actual_total} ({all_agree/actual_total*100:.1f}%)\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647,
     "referenced_widgets": [
      "d677be8e49f64f8aab5afb4ef69c7264",
      "9af660dd23434b63818eb7839d5247a7",
      "eed6a22d78fd420581822853ca630448",
      "2644bed47a9d46e5aa6ef43aef77aa82",
      "3d0dece50251421c9d979788dc668ae3",
      "898ab3d94ce34843931ede7790a47073",
      "b674fa014f8a4d65b850cf9c7a450b58",
      "9622b78450c94d10b54eb027c61905e0",
      "f878832c75c84e94bc30eefde410f156",
      "d4ff002789c8440a8459c96e2def137e",
      "54a71488e1664c52b87657ceecdba9c6",
      "e9cd2f78a0e84243972a55b5d3ce1246",
      "249c0dd3cb4a4135a261adbf60a112e5",
      "eefeb9d6152e461383459a7be48b652e",
      "8e6d543880b24c72b7dd55edf86708b6",
      "9e8c45754d3b4a669f17499553645872",
      "a1102da428764c6b9c3cac0ae6c1bfd2",
      "26899b40c00d49e0b4539f2331f81fe8",
      "2aa6dccac6c44b42a68c4e29048ab2a0",
      "d05afd7e72554780b931c43ed25e2cba",
      "d4676d10a60a47058e7f7b38c61d8f02",
      "3f139f5528c24c5592ce7cdc914e96ce",
      "f9ad8f327916468ab58463dca1527164",
      "507f2554c0f447b1a7cfeb78f81c459f",
      "f08949b74204451d818566d7f2f0a29a",
      "46010ad417da4d40b3571c272615759a",
      "4de8b246265a46e5b2a829dd49d9d574",
      "75c67aed4a024188aa7f962fcbec4a42",
      "052b579a7f6e47c7accc40bfd9f23a31",
      "e8f492eb1cc749508d826d1012760814",
      "d27ee41a78504b399720e7b18588bb47",
      "fde2b1484ba044518e67145af756b9a9",
      "359361e4fa2149f89166bf23d20dc024"
     ]
    },
    "id": "L86p9gxzyPMv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1770820710414,
     "user_tz": 300,
     "elapsed": 112725,
     "user": {
      "displayName": "Michael Hynes",
      "userId": "11107330966821812196"
     }
    },
    "outputId": "bf2fdcb7-bd58-4c31-f02f-bd9395d33e10"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Step 11: Export Results & Statistical Analysis (Stage 2 Enhancement 2.10)",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Stage 2 enhancement 2.10: CSV export and statistical analysis\nfrom scipy import stats\n\nif stats is not None and 'comparison_map' in stats:\n    comparison_map = stats['comparison_map']\n\n    # Build results dataframe\n    all_results = []\n    for img_id, results in comparison_map.items():\n        if 'cnn' in results and 'resnet' in results and 'mobilenet' in results:\n            row = {\n                'image_id': img_id,\n                'true_label': results['cnn']['true_label'],\n                'true_class': results['cnn']['true_class'],\n                'cnn_prediction': results['cnn']['predicted_name'],\n                'cnn_confidence': results['cnn']['confidence'],\n                'cnn_correct': int(results['cnn']['predicted_class'] == results['cnn']['true_label']),\n                'cnn_time_ms': results['cnn']['inference_time_ms'],\n                'resnet_prediction': results['resnet']['predicted_name'],\n                'resnet_confidence': results['resnet']['confidence'],\n                'resnet_correct': int(results['resnet']['predicted_class'] == results['resnet']['true_label']),\n                'resnet_time_ms': results['resnet']['inference_time_ms'],\n                'mobilenet_prediction': results['mobilenet']['predicted_name'],\n                'mobilenet_confidence': results['mobilenet']['confidence'],\n                'mobilenet_correct': int(results['mobilenet']['predicted_class'] == results['mobilenet']['true_label']),\n                'mobilenet_time_ms': results['mobilenet']['inference_time_ms'],\n            }\n            all_results.append(row)\n\n    df = pd.DataFrame(all_results)\n    df.to_csv('classification_results.csv', index=False)\n    print(f\"Exported {len(df)} results to classification_results.csv\")\n\n    # McNemar's test: CNN vs ResNet\n    print(\"\\n--- McNemar's Test: CNN vs ResNet ---\")\n    cnn_only = ((df['cnn_correct'] == 1) & (df['resnet_correct'] == 0)).sum()\n    resnet_only = ((df['cnn_correct'] == 0) & (df['resnet_correct'] == 1)).sum()\n\n    if cnn_only + resnet_only > 0:\n        mcnemar_stat = (abs(cnn_only - resnet_only) - 1)**2 / (cnn_only + resnet_only)\n        mcnemar_pvalue = 1 - stats.chi2.cdf(mcnemar_stat, df=1)\n        print(f\"  CNN correct, ResNet wrong: {cnn_only}\")\n        print(f\"  ResNet correct, CNN wrong: {resnet_only}\")\n        print(f\"  Chi-squared: {mcnemar_stat:.4f}, p-value: {mcnemar_pvalue:.4f}\")\n        if mcnemar_pvalue < 0.05:\n            print(\"  Result: Models are SIGNIFICANTLY different (p < 0.05)\")\n        else:\n            print(\"  Result: No significant difference (p >= 0.05)\")\n    else:\n        print(\"  Models made identical predictions on all images\")\n\n    # McNemar's test: CNN vs MobileNet\n    print(\"\\n--- McNemar's Test: CNN vs MobileNet ---\")\n    cnn_only_m = ((df['cnn_correct'] == 1) & (df['mobilenet_correct'] == 0)).sum()\n    mobilenet_only = ((df['cnn_correct'] == 0) & (df['mobilenet_correct'] == 1)).sum()\n\n    if cnn_only_m + mobilenet_only > 0:\n        mcnemar_stat = (abs(cnn_only_m - mobilenet_only) - 1)**2 / (cnn_only_m + mobilenet_only)\n        mcnemar_pvalue = 1 - stats.chi2.cdf(mcnemar_stat, df=1)\n        print(f\"  CNN correct, MobileNet wrong: {cnn_only_m}\")\n        print(f\"  MobileNet correct, CNN wrong: {mobilenet_only}\")\n        print(f\"  Chi-squared: {mcnemar_stat:.4f}, p-value: {mcnemar_pvalue:.4f}\")\n        if mcnemar_pvalue < 0.05:\n            print(\"  Result: Models are SIGNIFICANTLY different (p < 0.05)\")\n        else:\n            print(\"  Result: No significant difference (p >= 0.05)\")\n    else:\n        print(\"  Models made identical predictions on all images\")\n\n    # Inference time comparison\n    print(\"\\n--- Average Inference Time (ms) ---\")\n    print(f\"  CNN:       {df['cnn_time_ms'].mean():.2f} ms (std: {df['cnn_time_ms'].std():.2f})\")\n    print(f\"  ResNet:    {df['resnet_time_ms'].mean():.2f} ms (std: {df['resnet_time_ms'].std():.2f})\")\n    print(f\"  MobileNet: {df['mobilenet_time_ms'].mean():.2f} ms (std: {df['mobilenet_time_ms'].std():.2f})\")\n\n    # Inference time box plot\n    fig, ax = plt.subplots(figsize=(10, 5))\n    ax.boxplot([df['cnn_time_ms'], df['resnet_time_ms'], df['mobilenet_time_ms']],\n               labels=['CNN', 'ResNet', 'MobileNet'],\n               patch_artist=True,\n               boxprops=dict(facecolor='lightblue'))\n    ax.set_title('Inference Time Distribution by Agent', fontsize=14, fontweight='bold')\n    ax.set_ylabel('Inference Time (ms)')\n    ax.grid(axis='y', linestyle='--', alpha=0.7)\n    plt.show()\nelse:\n    print(\"No results to export. Run the system first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}